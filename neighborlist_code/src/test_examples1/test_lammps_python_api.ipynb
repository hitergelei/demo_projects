{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eebae2d-4b74-4800-86e7-03172543877f",
   "metadata": {},
   "source": [
    "### 1. 测试Python接口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4f19a2-f333-47aa-ba7b-ce4280fc50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "LAMMPS (29 Aug 2024)\n",
      "LAMMPS Version:  20240829\n",
      "Total wall time: 0:00:00\n",
      "Proc 0 out of 1 procs\n"
     ]
    }
   ],
   "source": [
    "import lammps\n",
    "from mpi4py import MPI\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "from lammps import lammps\n",
    "\n",
    "# 获取Python版本\n",
    "python_version = sys.version\n",
    "\n",
    "print(f\"Python version: {python_version}\")\n",
    "\n",
    "\n",
    "# NOTE: argv[0] is set by the lammps class constructor\n",
    "args = [\"-log\", \"none\"]\n",
    "\n",
    "# create LAMMPS instance\n",
    "lmp = lammps(cmdargs=args)\n",
    "\n",
    "# get and print numerical version code\n",
    "print(\"LAMMPS Version: \", lmp.version())\n",
    "\n",
    "# explicitly close and delete LAMMPS instance (optional)\n",
    "lmp.close()\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "print(\"Proc %d out of %d procs\" % (comm.Get_rank(),comm.Get_size()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d64776b2-d653-4a5c-94eb-339403a778ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.0.1\n",
      "CPU Information: 11.7\n",
      "CUDA is available.\n",
      "CUDA Version: 11.7\n",
      "CUDA Device Name: NVIDIA GeForce RTX 3080 Ti\n",
      "Number of CUDA Devices: 1\n",
      "CUDA Current Device: 0\n",
      "NVIDIA CUDA Driver Version: 515.76\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查 CPU 和 GPU 信息\n",
    "cpu_info = torch.__version__\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CPU Information: {torch.version.cuda}\")\n",
    "\n",
    "# 检查 GPU 信息\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of CUDA Devices: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA Current Device: {torch.cuda.current_device()}\")\n",
    "\n",
    "    # 获取 NVIDIA CUDA 驱动版本\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        driver_version = result.stdout.strip()\n",
    "        print(f\"NVIDIA CUDA Driver Version: {driver_version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get NVIDIA CUDA Driver Version: {e}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    print(\"NVIDIA GPU and CUDA driver information is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d71b8e-3ecd-4ebd-9d93-ab55b3757137",
   "metadata": {},
   "source": [
    "### 2. Python API提取原子信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef870a91-60fe-491d-a095-104c2835c1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2fc4c-3db9-45ec-80ce-e2906bc5f837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neighlist_env",
   "language": "python",
   "name": "neighlist_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
